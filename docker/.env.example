# by default the Dockerfile specifies these versions: 3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6+PTX
# however for me to work i had to specify the exact version for my card ( 2060 ) it was 7.5
# https://developer.nvidia.com/cuda-gpus you can find the version for your card here
TORCH_CUDA_ARCH_LIST=8.6

# the version used to install QUANT REPO from
QUANT_MODEL_URL=https://github.com/oobabooga/GPTQ-for-LLaMa
QUANT_SHA=53a2aeac935b7eef0e1451eb7b465fea4f318e7a
QUANT_BRANCH=cuda

# the version used to install text-generation-webui from
WEBUI_URL=https://github.com/oobabooga/text-generation-webui.git
WEBUI_SHA=b817f686d4f36c5a78152c966582ee79cb108b95
WEBUI_BRANCH=load-in-4bit

# ALPACA 4 BIT LORA VERSION
LORA_4BIT_URL=https://github.com/johnsmith0031/alpaca_lora_4bit.git
LORA_4BIT_SHA=2f704b93c961bf202937b10aac9322b092afdce0
LORA_4BIT_BRANCH=main

# the port the webui binds to on the host
HOST_PORT=7860
# the port the webui binds to inside the container
CONTAINER_PORT=7860

# the port the api binds to on the host
HOST_API_PORT=5000
# the port the api binds to inside the container
CONTAINER_API_PORT=5000

# the port the api stream endpoint binds to on the host
HOST_API_STREAM_PORT=5005
# the port the api stream endpoint binds to inside the container
CONTAINER_API_STREAM_PORT=5005
